# STEP 1: Import Libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import randint, uniform
import warnings
warnings.filterwarnings('ignore')

print("Libraries imported successfully")


# STEP 2: Load Dataset

from google.colab import files
uploaded = files.upload()

# Replace with the uploaded filename
df = pd.read_csv("CVD_cleaned.csv")

print("Dataset loaded successfully")
print("Shape:", df.shape)
df.head()


# STEP 3: Identify Target Column Automatically
possible_targets = ['cardio','Cardio','target','Target','health_status','Health','Outcome','y']
cols = df.columns.str.lower()
target_col = None

for t in possible_targets:
    if t.lower() in cols:
        target_col = [c for c in df.columns if c.lower() == t.lower()][0]
        break

# If no known target column is found, assume last column
if target_col is None:
    target_col = df.columns[-1]

print("Target column detected:", target_col)

# Separate features and labels
X = df.drop(columns=[target_col])
y = df[target_col]

print("\nFeatures shape:", X.shape)
print("Target distribution:\n", y.value_counts(normalize=True))


print("Target value counts:\n", y.value_counts())

value_counts = y.value_counts()
valid_classes = value_counts[value_counts >= 2].index
X = X[y.isin(valid_classes)]
y = y[y.isin(valid_classes)]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

print("X_train:", X_train.shape)
print("X_test :", X_test.shape)
print("y_train distribution:\n", y_train.value_counts(normalize=True))
print("Dataset split successfully")


# STEP 3.1: Encode categorical (string) columns
from sklearn.preprocessing import LabelEncoder

# Identify non-numeric columns
categorical_cols = X.select_dtypes(include=['object']).columns
print("Categorical columns:", list(categorical_cols))

# Apply label encoding to all categorical columns
le = LabelEncoder()
for col in categorical_cols:
    X[col] = le.fit_transform(X[col])

print("After encoding, dataset looks like:")
print(X.head())

# STEP 3: Identify Target Column Automatically
possible_targets = ['cardio','Cardio','target','Target','health_status','Health','Outcome','y']
cols = df.columns.str.lower()
target_col = None

for t in possible_targets:
    if t.lower() in cols:
        target_col = [c for c in df.columns if c.lower() == t.lower()][0]
        break

if target_col is None:
    target_col = df.columns[-1]

print("Target column detected:", target_col)

# Separate features and labels
X = df.drop(columns=[target_col])
y = df[target_col]

# STEP 3.1: Encode categorical columns in X
from sklearn.preprocessing import LabelEncoder

categorical_cols = X.select_dtypes(include=['object']).columns
print("Categorical columns:", list(categorical_cols))

le = LabelEncoder()
for col in categorical_cols:
    X[col] = le.fit_transform(X[col])

print("After encoding, dataset is fully numeric:")
print(X.head())

# If target column is categorical, encode it too
if y.dtype == "object":
    y = LabelEncoder().fit_transform(y)

print("Final target distribution:\n", pd.Series(y).value_counts())


# STEP 4: Train-Test Split (80:20)
from sklearn.model_selection import train_test_split

# Check class counts and remove classes with <2 samples if necessary
value_counts = pd.Series(y).value_counts()
valid_classes = value_counts[value_counts >= 2].index
X = X[y.isin(valid_classes)]
y = y[y.isin(valid_classes)]

# Split dataset safely
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

print("X_train:", X_train.shape)
print("X_test :", X_test.shape)
print("Dataset split successfully")


param_distributions = {
    "SVM": {
        "svc__C": uniform(0.1, 10),
        "svc__gamma": ["scale", "auto"],
        "svc__kernel": ["rbf", "poly", "sigmoid"]
    },
    "Random Forest": {
        "rf__n_estimators": randint(50, 200),
        "rf__max_depth": randint(3, 20),
        "rf__min_samples_split": randint(2, 8),
        "rf__min_samples_leaf": randint(1, 5)
    },
    "Logistic Regression": {
        "log__C": uniform(0.01, 10),
        "log__penalty": ["l2"],
        "log__solver": ["lbfgs", "saga"]
    }
}
